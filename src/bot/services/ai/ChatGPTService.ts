import { OpenAI } from "openai";
import { BaseAIService, AIMessage, AIResponse } from "./BaseAIService";
import { prisma } from "../../../utils/prismaClient";

export class ChatGPTService extends BaseAIService {
  private client: OpenAI;

  constructor() {
    super();
    this.client = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY || "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",
    });
  }

  getName(): string {
    return "ChatGPT";
  }

  validateConfig(): boolean {
    return !!process.env.OPENAI_API_KEY;
  }

  async chat(messages: AIMessage[], userId: string): Promise<AIResponse> {
    try {
      // Get user preferences from database
      const user = await prisma.user.findUnique({
        where: { telegramId: parseInt(userId) },
      });

      const completion = await this.client.chat.completions.create({
        model: user?.gptSettings?.model || "gpt-4.1-mini",
        messages: messages,
        temperature: 0.4,
        max_tokens: 2000,
      });

      const content = completion.choices[0]?.message?.content;
      if (!content) {
        throw new Error("No response content received from OpenAI");
      }

      return {
        content,
        usage: {
          promptTokens: completion.usage?.prompt_tokens || 0,
          completionTokens: completion.usage?.completion_tokens || 0,
          totalTokens: completion.usage?.total_tokens || 0,
        },
      };
    } catch (error) {
      console.error("ChatGPT Service Error:", error);
      
          // Fallback to demo response if API fails
          const lastMessage = messages[messages.length - 1];
          return {
            content: `ü§ñ *ChatGPT GPT-4.1-mini (Fallback Mode)*\n\n–í–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ —Å API, –Ω–æ –≤–æ—Ç –¥–µ–º–æ-–æ—Ç–≤–µ—Ç:\n\n–í—ã –Ω–∞–ø–∏—Å–∞–ª–∏: "${lastMessage.content}"\n\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à OPENAI_API_KEY –≤ .env —Ñ–∞–π–ª–µ.\n\nüí° ChatGPT GPT-4.1-mini - —Å–∞–º–∞—è —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å –ª—É—á—à–∏–º –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º –∏ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ–º!`,
            usage: {
              promptTokens: 50,
              completionTokens: 100,
              totalTokens: 150,
            },
          };
    }
  }

  // üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π DALL-E
  async generateImage(prompt: string, model: string = "dall-e-3", size: string = "1024x1024"): Promise<string> {
    try {
      const response = await this.client.images.generate({
        model: model,
        prompt: prompt,
        n: 1,
        size: size as any,
        quality: model === "dall-e-3" ? "standard" : undefined,
      });

      const imageUrl = response.data?.[0]?.url;
      if (!imageUrl) {
        throw new Error("No image URL received from OpenAI");
      }

      return imageUrl;

    } catch (error: any) {
      console.error("DALL-E Image Generation Error:", error);
      
      if (error.code === 'content_policy_violation') {
        throw new Error("–í–∞—à –∑–∞–ø—Ä–æ—Å –Ω–∞—Ä—É—à–∞–µ—Ç –ø–æ–ª–∏—Ç–∏–∫—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ.");
      }
      
      throw new Error(`–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: ${error.message || "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"}`);
    }
  }

  // üëÅÔ∏è –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π GPT-4V
  async analyzeImage(imageUrl: string, prompt: string): Promise<AIResponse> {
    try {
      const completion = await this.client.chat.completions.create({
        model: "gpt-4-vision-preview",
        messages: [
          {
            role: "user",
            content: [
              { type: "text", text: prompt },
              { type: "image_url", image_url: { url: imageUrl } }
            ]
          }
        ],
        max_tokens: 1000,
      });

      const content = completion.choices[0]?.message?.content;
      if (!content) {
        throw new Error("No response content received from OpenAI Vision");
      }

      return {
        content,
        usage: {
          promptTokens: completion.usage?.prompt_tokens || 0,
          completionTokens: completion.usage?.completion_tokens || 0,
          totalTokens: completion.usage?.total_tokens || 0,
        },
      };

    } catch (error: any) {
      console.error("GPT-4V Analysis Error:", error);
      throw new Error(`–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: ${error.message || "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"}`);
    }
  }

  // üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper
  async transcribeAudio(filePath: string, language: string = 'ru'): Promise<AIResponse> {
    try {
      const fs = await import('fs');
      const fileStream = fs.createReadStream(filePath);

      const transcription = await this.client.audio.transcriptions.create({
        file: fileStream,
        model: "whisper-1",
        language: language,
        response_format: "text"
      });

      return {
        content: transcription as string,
        usage: {
          promptTokens: 0,
          completionTokens: 0,
          totalTokens: 0,
        },
      };

    } catch (error: any) {
      console.error("Whisper Transcription Error:", error);
      throw new Error(`–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –∞—É–¥–∏–æ: ${error.message || "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"}`);
    }
  }

  // üìÑ –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
  async analyzeFile(fileContent: string, fileName: string, prompt: string, userId: string): Promise<AIResponse> {
    try {
      // Get user preferences from database
      const user = await prisma.user.findUnique({
        where: { telegramId: parseInt(userId) },
      });

      const messages: AIMessage[] = [
        {
          role: "system",
          content: "–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –∏ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –Ω–∏—Ö. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."
        },
        {
          role: "user",
          content: `–£ –º–µ–Ω—è –µ—Å—Ç—å —Ñ–∞–π–ª "${fileName}" —Å–æ —Å–ª–µ–¥—É—é—â–∏–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º:\n\n${fileContent}\n\n${prompt}`
        }
      ];

      const completion = await this.client.chat.completions.create({
        model: user?.gptSettings?.model || "gpt-4o-mini",
        messages: messages,
        temperature: 0.4,
        max_tokens: 2000,
      });

      const content = completion.choices[0]?.message?.content;
      if (!content) {
        throw new Error("No response content received from OpenAI");
      }

      return {
        content,
        usage: {
          promptTokens: completion.usage?.prompt_tokens || 0,
          completionTokens: completion.usage?.completion_tokens || 0,
          totalTokens: completion.usage?.total_tokens || 0,
        },
      };

    } catch (error: any) {
      console.error("File Analysis Error:", error);
      throw new Error(`–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞: ${error.message || "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"}`);
    }
  }
}
